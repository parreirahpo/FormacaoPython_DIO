{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuxI9w1/zCvV+583Qw5DQg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parreirahpo/FormacaoPython_DIO/blob/main/Azure_DevOps_Extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalando as dependências necessárias**"
      ],
      "metadata": {
        "id": "DSbuX02eLXsW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEnj-xIvLXDz"
      },
      "outputs": [],
      "source": [
        "!pip install azure-devops\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizando a autenticação com o Azure DevOps através de Personal Access Token**"
      ],
      "metadata": {
        "id": "bbFerP8xLg4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.devops.connection import Connection\n",
        "from msrest.authentication import BasicAuthentication\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "organization_url = f'https://dev.azure.com/{userdata.get(\"azureOrg\")}'\n",
        "project_name = userdata.get(\"azureProject\")\n",
        "personal_access_token = userdata.get(\"azurePat\")\n",
        "\n",
        "credentials = BasicAuthentication('', personal_access_token)\n",
        "connection = Connection(base_url=organization_url, creds=credentials)\n",
        "wit_client = connection.clients.get_work_item_tracking_client()\n"
      ],
      "metadata": {
        "id": "c9BGX7hzLmtx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analisa o AzureDevOps em busca de todos os tipos de Work Items e seus respectivos campos, e então armazena essas informações em um Excel.**"
      ],
      "metadata": {
        "id": "yDlXNJAFMjQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "import pandas as pd\n",
        "\n",
        "def get_field_details(url, personal_access_token):\n",
        "    encoded_pat = base64.b64encode((\":\" + personal_access_token).encode(\"ascii\")).decode(\"ascii\")\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
        "        'Authorization': 'Basic ' + encoded_pat,\n",
        "        'Accept': 'application/json'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "# Obtém todos os tipos de work items do projeto #\n",
        "work_item_types = wit_client.get_work_item_types(project_name)\n",
        "\n",
        "# Dicionário para armazenar os dataframes de cada tipo de work item #\n",
        "work_item_fields_dfs = {}\n",
        "\n",
        "for work_item_type in work_item_types:\n",
        "    fields = work_item_type.fields\n",
        "    fields_data = []\n",
        "\n",
        "    # Itera sobre cada field e faz uma requisição para obter os detalhes #\n",
        "    for field in fields:\n",
        "        try:\n",
        "            field_details = get_field_details(field.url, personal_access_token)\n",
        "            field_info = {\n",
        "                \"Name\": field_details.get('name', 'None'),\n",
        "                \"Reference Name\": field_details.get('referenceName', 'None'),\n",
        "                \"Type\": field_details.get('type', 'None'),\n",
        "                \"Description\": field_details.get('description', '')\n",
        "            }\n",
        "            fields_data.append(field_info)\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            print(f\"HTTP error occurred for work item type {work_item_type.name} and field {field.name}: {http_err} - URL: {field.url}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred for work item type {work_item_type.name} and field {field.name}: {e} - URL: {field.url}\")\n",
        "\n",
        "    # Cria um dataframe a partir dos dados coletados #\n",
        "    fields_df = pd.DataFrame(fields_data, columns=[\"Name\", \"Reference Name\", \"Type\", \"Description\"])\n",
        "\n",
        "    # Armazena o dataframe no dicionário com o nome do tipo de work item como chave #\n",
        "    work_item_fields_dfs[work_item_type.name] = fields_df\n",
        "\n",
        "# Salva todos os dataframes em um único arquivo excel com diferentes abas #\n",
        "output_filename = 'work_item_types.xlsx'\n",
        "with pd.ExcelWriter(output_filename) as writer:\n",
        "    for work_item_type, df in work_item_fields_dfs.items():\n",
        "        df.to_excel(writer, sheet_name=work_item_type, index=False)\n"
      ],
      "metadata": {
        "id": "BpYSSLYqMj9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Através de uma query criada no Azure DevOps, busca as informações de cada Work Item retornado.**"
      ],
      "metadata": {
        "id": "p9BRmzo1rJ05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtém os work items através de um query_id do Azure DevOps #\n",
        "query_id = userdata.get(\"azureQueryId\")\n",
        "query_results = wit_client.query_by_id(query_id)\n",
        "work_items = query_results.work_items\n",
        "\n",
        "# Dicionário para armazenar os dataframes dos estados atuais de cada tipo de work item #\n",
        "work_item_current_state_dfs = {}\n",
        "\n",
        "# Processa cada work item retornado pela query #\n",
        "for work_item_ref in work_items:\n",
        "    work_item_id = work_item_ref.id\n",
        "    work_item_details = wit_client.get_work_item(work_item_id, expand='All')\n",
        "    work_item_type = work_item_details.fields['System.WorkItemType']\n",
        "\n",
        "    # Obtém o dataframe dos fields para o tipo de work item #\n",
        "    fields_df = work_item_fields_dfs.get(work_item_type)\n",
        "    if fields_df is None:\n",
        "        continue\n",
        "\n",
        "    # Dicionário para armazenar os dados do estado atual do work item #\n",
        "    current_state_data = {\n",
        "        'Type': work_item_type,\n",
        "        'ID': work_item_id\n",
        "    }\n",
        "\n",
        "    # Preenche o dicionário com os dados atuais do work item #\n",
        "    for _, field_info in fields_df.iterrows():\n",
        "        field_name = field_info['Reference Name']\n",
        "        field_value = work_item_details.fields.get(field_name, 'None')\n",
        "\n",
        "        # Verifica se o valor é um dicionário e contém 'displayName' para capturar apenas o nome do usuário #\n",
        "        if isinstance(field_value, dict) and 'displayName' in field_value:\n",
        "            field_value = field_value['displayName']\n",
        "        current_state_data[field_info['Name']] = field_value\n",
        "\n",
        "    # Cria um dataframe a partir dos dados do estado atual #\n",
        "    current_state_df = pd.DataFrame([current_state_data])\n",
        "\n",
        "    # Armazena o dataframe no dicionário com o nome do tipo de work item como chave #\n",
        "    if work_item_type not in work_item_current_state_dfs:\n",
        "        work_item_current_state_dfs[work_item_type] = []\n",
        "    work_item_current_state_dfs[work_item_type].append(current_state_df)\n",
        "\n",
        "# Salva todos os dataframes de estados atuais em um único arquivo excel #\n",
        "output_filename = 'work_item_current_states.xlsx'\n",
        "with pd.ExcelWriter(output_filename) as writer:\n",
        "    for work_item_type, dfs in work_item_current_state_dfs.items():\n",
        "        combined_df = pd.concat(dfs, ignore_index=True)\n",
        "        combined_df.to_excel(writer, sheet_name=work_item_type, index=False)\n"
      ],
      "metadata": {
        "id": "7H3uX_0mrKO9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Através de uma query criada no Azure DevOps, busca pelas modificações que ocorreram em cada um dos tipos de Work Item retornados.**"
      ],
      "metadata": {
        "id": "WHCQgs-3s61F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtém os work items através de um query_id do Azure DevOps #\n",
        "query_id = userdata.get(\"azureQueryId\")\n",
        "query_results = wit_client.query_by_id(query_id)\n",
        "work_items = query_results.work_items\n",
        "\n",
        "# Dicionário para armazenar os dataframes de revisões de cada tipo de work item #\n",
        "work_item_revisions_dfs = {}\n",
        "\n",
        "# Processa cada work item retornado pela query #\n",
        "for work_item_ref in work_items:\n",
        "    work_item_id = work_item_ref.id\n",
        "    work_item_details = wit_client.get_work_item(work_item_id, expand='All')\n",
        "    work_item_type = work_item_details.fields['System.WorkItemType']\n",
        "\n",
        "    # Obtém o dataframe dos fields para o tipo de work item #\n",
        "    fields_df = work_item_fields_dfs.get(work_item_type)\n",
        "    if fields_df is None:\n",
        "        continue\n",
        "\n",
        "    # Obtém o histórico de revisões para o work item #\n",
        "    revisions = wit_client.get_revisions(work_item_id)\n",
        "\n",
        "    # Lista para armazenar os dados das revisões #\n",
        "    revisions_data = []\n",
        "\n",
        "    for revision in revisions:\n",
        "        revision_data = {\n",
        "            'Type': work_item_type,\n",
        "            'ID': work_item_id,\n",
        "            'REV ID': revision.rev\n",
        "        }\n",
        "        for _, field_info in fields_df.iterrows():\n",
        "            field_name = field_info['Reference Name']\n",
        "            field_value = revision.fields.get(field_name, work_item_details.fields.get(field_name, 'None'))\n",
        "            # Verifica se o valor é um dicionário e contém 'displayName' para capturar apenas o nome do usuário #\n",
        "            if isinstance(field_value, dict) and 'displayName' in field_value:\n",
        "                field_value = field_value['displayName']\n",
        "            revision_data[field_info['Name']] = field_value\n",
        "        revisions_data.append(revision_data)\n",
        "\n",
        "    # Cria um dataframe a partir dos dados das revisões #\n",
        "    revisions_df = pd.DataFrame(revisions_data)\n",
        "\n",
        "    # Armazena o dataframe no dicionário com o nome do tipo de work item como chave #\n",
        "    if work_item_type not in work_item_revisions_dfs:\n",
        "        work_item_revisions_dfs[work_item_type] = []\n",
        "    work_item_revisions_dfs[work_item_type].append(revisions_df)\n",
        "\n",
        "# Salva todos os dataframes de revisões em um único arquivo excel #\n",
        "output_filename = 'work_item_revisions.xlsx'\n",
        "with pd.ExcelWriter(output_filename) as writer:\n",
        "    for work_item_type, dfs in work_item_revisions_dfs.items():\n",
        "        combined_df = pd.concat(dfs, ignore_index=True)\n",
        "        combined_df.to_excel(writer, sheet_name=work_item_type, index=False)"
      ],
      "metadata": {
        "id": "IxxC9FJFs7Su"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analisa o retorno das revisões de cada Work Item retornado anteriormente, e cria um novo arquivo Excel para conter apenas as alterações.**"
      ],
      "metadata": {
        "id": "EqY1FYMB7Tq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_changes(df):\n",
        "    df.sort_values(by=['Type', 'ID', 'REV ID'], inplace=True)\n",
        "    work_item_changes_dfs = {}\n",
        "\n",
        "    # Agrupa por 'Type' e 'ID', que são as nossas chaves de identificação de cada Work Item #\n",
        "    grouped = df.groupby(['Type', 'ID'])\n",
        "\n",
        "    for (type_id, id), group in grouped:\n",
        "        if len(group) < 2:\n",
        "            continue  # Ignora se houver apenas uma revisão, já que não houve modificações #\n",
        "\n",
        "        previous_row = None\n",
        "        for index, current_row in group.iterrows():\n",
        "            if previous_row is not None:\n",
        "                changes = {'Type': type_id, 'ID': id}  # Inicializa com Type e ID, para mantermos estas informações de identificação #\n",
        "                for column in group.columns:\n",
        "                    if column not in ['Type', 'ID', 'REV ID'] and current_row[column] != previous_row[column]:\n",
        "                        changes[column] = f\"{previous_row[column]} to {current_row[column]}\"\n",
        "\n",
        "                if len(changes) > 2:  # Verifica se existem alterações além de Type e ID que inicializamos anteriormente #\n",
        "                    changes['From REV ID'] = previous_row['REV ID']\n",
        "                    changes['To REV ID'] = current_row['REV ID']\n",
        "                    changes['Detail'] = f\"From REV {previous_row['REV ID']} to {current_row['REV ID']}\"\n",
        "                    unique_key = f\"{type_id}-{id}\"\n",
        "\n",
        "                    if unique_key not in work_item_changes_dfs:\n",
        "                        work_item_changes_dfs[unique_key] = []\n",
        "\n",
        "                    work_item_changes_dfs[unique_key].append(changes)\n",
        "\n",
        "            previous_row = current_row\n",
        "\n",
        "    return work_item_changes_dfs\n",
        "\n",
        "work_item_changes_dfs = analyze_changes(combined_df) # combined_df é nosso dataframe gerado anteriormente com as revisões #\n",
        "\n",
        "# Salva as mudanças em um novo arquivo excel #\n",
        "output_changes_filename = 'work_item_changes.xlsx'\n",
        "with pd.ExcelWriter(output_changes_filename) as writer:\n",
        "    for unique_key, changes_list in work_item_changes_dfs.items():\n",
        "        if changes_list:  # Verifica se existe alguma alteração registrada #\n",
        "            df = pd.DataFrame(changes_list)\n",
        "            df.to_excel(writer, sheet_name=unique_key[:31], index=False)  # Limita o nome da sheet a 31 caracteres #\n",
        "\n"
      ],
      "metadata": {
        "id": "VzxFAmt47UEI"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}